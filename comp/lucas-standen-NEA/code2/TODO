make the tokenizer work, it needs to call recursively whenever it see's a '(' execept the first
expression, perhaps cut them off before the call
